{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a50ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas numpy kafka-python scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1af8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from kafka import KafkaConsumer  # For data ingestion (requires kafka-python library)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sqlite3  # For local storage simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d29076a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data Ingestion\n",
    "def ingest_data():\n",
    "    \"\"\"\n",
    "    Simulates data ingestion from a Kafka topic. \n",
    "    Returns a mock dataframe for demonstration or real data if Kafka is configured.\n",
    "    \"\"\"\n",
    "    # Mock data for testing without Kafka\n",
    "    data = {\n",
    "        \"timestamp\": pd.date_range(start=\"2025-01-01\", periods=10, freq=\"D\"),\n",
    "        \"sensor_reading\": np.random.randint(50, 100, size=10),\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    print(\"Data Ingested:\")\n",
    "    print(df)\n",
    "    return df\n",
    "\n",
    "    # Uncomment the following to use Kafka for real data ingestion\n",
    "    # consumer = KafkaConsumer('your_topic', \n",
    "    #                          bootstrap_servers=['localhost:9092'],\n",
    "    #                          value_deserializer=lambda m: json.loads(m.decode('ascii')))\n",
    "    # \n",
    "    # data_list = []\n",
    "    # for message in consumer:\n",
    "    #     data_list.append(message.value)\n",
    "    # \n",
    "    # if not data_list:\n",
    "    #     raise ValueError(\"No data received from Kafka\")\n",
    "    # \n",
    "    # df = pd.DataFrame(data_list)\n",
    "    # consumer.close()\n",
    "    # return df\n",
    "\n",
    "# 2. Data Processing (Simple ETL)\n",
    "def process_data(df):\n",
    "    \"\"\"\n",
    "    Simulates processing by normalizing the sensor readings.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        raise ValueError(\"DataFrame is empty, cannot process data.\")\n",
    "    \n",
    "    df[\"normalized_reading\"] = (df[\"sensor_reading\"] - df[\"sensor_reading\"].min()) / (\n",
    "        df[\"sensor_reading\"].max() - df[\"sensor_reading\"].min()\n",
    "    )\n",
    "    print(\"\\nData Processed (Normalized):\")\n",
    "    print(df)\n",
    "    return df\n",
    "\n",
    "# 3. Data Storage\n",
    "def store_data(df):\n",
    "    \"\"\"\n",
    "    Stores processed data into a local SQLite database.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        raise ValueError(\"DataFrame is empty, cannot store data.\")\n",
    "    \n",
    "    conn = sqlite3.connect(\"data_pipeline.db\")\n",
    "    df.to_sql(\"sensor_data\", conn, if_exists=\"replace\", index=False)\n",
    "    conn.close()\n",
    "    print(\"\\nData Stored in SQLite Database.\")\n",
    "\n",
    "# 4. AI Model Integration (Simple Predictive Model)\n",
    "def ai_model_prediction(df):\n",
    "    \"\"\"\n",
    "    Uses a linear regression model to predict future sensor readings based on time.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        raise ValueError(\"DataFrame is empty, cannot make predictions.\")\n",
    "    \n",
    "    # Convert timestamp to ordinal for numeric prediction\n",
    "    df[\"timestamp_ordinal\"] = pd.to_datetime(df[\"timestamp\"]).apply(pd.Timestamp.toordinal)\n",
    "\n",
    "    # Train a simple linear regression model\n",
    "    model = LinearRegression()\n",
    "    X = df[[\"timestamp_ordinal\"]]\n",
    "    y = df[\"sensor_reading\"]\n",
    "    try:\n",
    "        model.fit(X, y)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error in model fitting: {e}\")\n",
    "        return\n",
    "\n",
    "    # Predict future readings for the next 5 days\n",
    "    future_dates = pd.date_range(start=df[\"timestamp\"].max(), periods=5, freq=\"D\")\n",
    "    future_ordinals = future_dates.map(pd.Timestamp.toordinal)\n",
    "    future_readings = model.predict(future_ordinals.values.reshape(-1, 1))\n",
    "\n",
    "    print(\"\\nAI Model Predictions (Next 5 Days):\")\n",
    "    for date, reading in zip(future_dates, future_readings):\n",
    "        print(f\"Date: {date}, Predicted Reading: {reading:.2f}\")\n",
    "\n",
    "# Main Pipeline Execution\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Step 1: Ingest data\n",
    "        data = ingest_data()\n",
    "\n",
    "        # Step 2: Process data\n",
    "        processed_data = process_data(data)\n",
    "\n",
    "        # Step 3: Store data\n",
    "        store_data(processed_data)\n",
    "\n",
    "        # Step 4: AI Model Prediction\n",
    "        ai_model_prediction(processed_data)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fa4864",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
